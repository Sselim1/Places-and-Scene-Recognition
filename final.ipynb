{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9da625",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-28T22:59:44.204241Z",
     "iopub.status.busy": "2021-12-28T22:59:44.202143Z",
     "iopub.status.idle": "2021-12-28T22:59:51.039201Z",
     "shell.execute_reply": "2021-12-28T22:59:51.038449Z",
     "shell.execute_reply.started": "2021-12-28T21:40:18.897254Z"
    },
    "papermill": {
     "duration": 6.902378,
     "end_time": "2021-12-28T22:59:51.039415",
     "exception": false,
     "start_time": "2021-12-28T22:59:44.137037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "from keras.backend import image_data_format\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalMaxPooling2D, AveragePooling2D, concatenate, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import get_file\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373c3108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T22:59:51.106785Z",
     "iopub.status.busy": "2021-12-28T22:59:51.105653Z",
     "iopub.status.idle": "2021-12-28T22:59:51.107920Z",
     "shell.execute_reply": "2021-12-28T22:59:51.108684Z",
     "shell.execute_reply.started": "2021-12-28T21:40:25.107604Z"
    },
    "papermill": {
     "duration": 0.036819,
     "end_time": "2021-12-28T22:59:51.108883",
     "exception": false,
     "start_time": "2021-12-28T22:59:51.072064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161495dc",
   "metadata": {
    "papermill": {
     "duration": 0.029441,
     "end_time": "2021-12-28T22:59:51.166898",
     "exception": false,
     "start_time": "2021-12-28T22:59:51.137457",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f3a194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T22:59:51.231945Z",
     "iopub.status.busy": "2021-12-28T22:59:51.231221Z",
     "iopub.status.idle": "2021-12-28T23:00:23.824833Z",
     "shell.execute_reply": "2021-12-28T23:00:23.824192Z",
     "shell.execute_reply.started": "2021-12-28T21:40:25.124907Z"
    },
    "papermill": {
     "duration": 32.630125,
     "end_time": "2021-12-28T23:00:23.825003",
     "exception": false,
     "start_time": "2021-12-28T22:59:51.194878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crea(img):\n",
    "  if(img==0):\n",
    "    return 0\n",
    "  elif(img==1):\n",
    "    return 1\n",
    "  elif(img==2):\n",
    "    return 2\n",
    "  elif(img==3):\n",
    "    return 3\n",
    "  elif(img==4):\n",
    "    return 4\n",
    "  else:\n",
    "    return 5\n",
    "data=pd.read_csv('../input/ci-sc22-places-and-scene-recognition/train.csv')\n",
    "filenames = tf.io.gfile.glob('../input/ci-sc22-places-and-scene-recognition/train_images/train_images/*')\n",
    "image_data_train = pd.DataFrame(data={'filename': filenames, 'class': [crea(np.array(data['label'][data['image_name'] == x.split('/')[-1]])) for x in filenames]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4439a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:00:23.890745Z",
     "iopub.status.busy": "2021-12-28T23:00:23.889492Z",
     "iopub.status.idle": "2021-12-28T23:00:23.892335Z",
     "shell.execute_reply": "2021-12-28T23:00:23.892945Z",
     "shell.execute_reply.started": "2021-12-28T21:40:56.442114Z"
    },
    "papermill": {
     "duration": 0.038631,
     "end_time": "2021-12-28T23:00:23.893107",
     "exception": false,
     "start_time": "2021-12-28T23:00:23.854476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labele_image(df):\n",
    "    images = []\n",
    "    for file in df['filename']:\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image,IMAGE_SIZE)\n",
    "        images.append(image)\n",
    "    images = np.array(images)\n",
    "    \n",
    "    labels = df.loc[:, 'class']\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3d19f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:00:23.958250Z",
     "iopub.status.busy": "2021-12-28T23:00:23.957480Z",
     "iopub.status.idle": "2021-12-28T23:00:23.971824Z",
     "shell.execute_reply": "2021-12-28T23:00:23.972814Z",
     "shell.execute_reply.started": "2021-12-28T21:40:56.454113Z"
    },
    "papermill": {
     "duration": 0.050052,
     "end_time": "2021-12-28T23:00:23.973083",
     "exception": false,
     "start_time": "2021-12-28T23:00:23.923031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample:  13627 {3: 2430, 2: 2366, 5: 2306, 4: 2227, 1: 2196, 0: 2102}\n"
     ]
    }
   ],
   "source": [
    "image_data_train=shuffle(image_data_train)\n",
    "\n",
    "print('Train sample: ', len(image_data_train['class']), dict(image_data_train['class'].value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d9d61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:00:24.041607Z",
     "iopub.status.busy": "2021-12-28T23:00:24.040624Z",
     "iopub.status.idle": "2021-12-28T23:01:34.805220Z",
     "shell.execute_reply": "2021-12-28T23:01:34.805906Z",
     "shell.execute_reply.started": "2021-12-28T21:40:56.475470Z"
    },
    "papermill": {
     "duration": 70.801365,
     "end_time": "2021-12-28T23:01:34.806112",
     "exception": false,
     "start_time": "2021-12-28T23:00:24.004747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (13627, 224, 224, 3)\n",
      "Shape of train set: (13627,)\n",
      "Shape of train set: (3000, 224, 224, 3)\n",
      "Shape of train set: (3000,)\n"
     ]
    }
   ],
   "source": [
    "image_data_val=image_data_train.sample(3000)\n",
    "train_images, train_labels = labele_image(image_data_train)\n",
    "val_images, val_labels = labele_image(image_data_val)\n",
    "\n",
    "print(f'Shape of train set: {train_images.shape}')\n",
    "print(f'Shape of train set: {train_labels.shape}')\n",
    "print(f'Shape of train set: {val_images.shape}')\n",
    "print(f'Shape of train set: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2a10c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:01:34.912002Z",
     "iopub.status.busy": "2021-12-28T23:01:34.896499Z",
     "iopub.status.idle": "2021-12-28T23:01:34.933597Z",
     "shell.execute_reply": "2021-12-28T23:01:34.933090Z",
     "shell.execute_reply.started": "2021-12-28T21:42:21.361255Z"
    },
    "papermill": {
     "duration": 0.097287,
     "end_time": "2021-12-28T23:01:34.933728",
     "exception": false,
     "start_time": "2021-12-28T23:01:34.836441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "BASE_WEIGHT_URL = 'https://github.com/myutwo150/keras-inception-resnet-v2/releases/download/v0.1/'\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "    \"\"\"Utility function to apply conv + BN.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        kernel_size: kernel size as in `Conv2D`.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        activation: activation in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_Activation'`\n",
    "            for the activation and `name + '_BatchNorm'` for the\n",
    "            batch norm layer.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    x = Conv2D(filters,\n",
    "               kernel_size,\n",
    "               strides=strides,\n",
    "               padding=padding,\n",
    "               use_bias=use_bias,\n",
    "               name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = _generate_layer_name('BatchNorm', prefix=name)\n",
    "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = _generate_layer_name('Activation', prefix=name)\n",
    "        x = Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _generate_layer_name(name, branch_idx=None, prefix=None):\n",
    "    \"\"\"Utility function for generating layer names.\n",
    "    If `prefix` is `None`, returns `None` to use default automatic layer names.\n",
    "    Otherwise, the returned layer name is:\n",
    "        - PREFIX_NAME if `branch_idx` is not given.\n",
    "        - PREFIX_Branch_0_NAME if e.g. `branch_idx=0` is given.\n",
    "    # Arguments\n",
    "        name: base layer name string, e.g. `'Concatenate'` or `'Conv2d_1x1'`.\n",
    "        branch_idx: an `int`. If given, will add e.g. `'Branch_0'`\n",
    "            after `prefix` and in front of `name` in order to identify\n",
    "            layers in the same block but in different branches.\n",
    "        prefix: string prefix that will be added in front of `name` to make\n",
    "            all layer names unique (e.g. which block this layer belongs to).\n",
    "    # Returns\n",
    "        The layer name.\n",
    "    \"\"\"\n",
    "    if prefix is None:\n",
    "        return None\n",
    "    if branch_idx is None:\n",
    "        return '_'.join((prefix, name))\n",
    "    return '_'.join((prefix, 'Branch', str(branch_idx), name))\n",
    "\n",
    "\n",
    "def _inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    \"\"\"Adds a Inception-ResNet block.\n",
    "    This function builds 3 types of Inception-ResNet blocks mentioned\n",
    "    in the paper, controlled by the `block_type` argument (which is the\n",
    "    block name used in the official TF-slim implementation):\n",
    "        - Inception-ResNet-A: `block_type='Block35'`\n",
    "        - Inception-ResNet-B: `block_type='Block17'`\n",
    "        - Inception-ResNet-C: `block_type='Block8'`\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        scale: scaling factor to scale the residuals before adding\n",
    "            them to the shortcut branch.\n",
    "        block_type: `'Block35'`, `'Block17'` or `'Block8'`, determines\n",
    "            the network structure in the residual branch.\n",
    "        block_idx: used for generating layer names.\n",
    "        activation: name of the activation function to use at the end\n",
    "            of the block (see [activations](../activations.md)).\n",
    "            When `activation=None`, no activation is applied\n",
    "            (i.e., \"linear\" activation: `a(x) = x`).\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    # Raises\n",
    "        ValueError: if `block_type` is not one of `'Block35'`,\n",
    "            `'Block17'` or `'Block8'`.\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    if block_idx is None:\n",
    "        prefix = None\n",
    "    else:\n",
    "        prefix = '_'.join((block_type, str(block_idx)))\n",
    "    name_fmt = partial(_generate_layer_name, prefix=prefix)\n",
    "\n",
    "    if block_type == 'Block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "        branch_2 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 48, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "        branch_2 = conv2d_bn(branch_2, 64, 3, name=name_fmt('Conv2d_0c_3x3', 2))\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'Block17':\n",
    "        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 160, [1, 7], name=name_fmt('Conv2d_0b_1x7', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [7, 1], name=name_fmt('Conv2d_0c_7x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'Block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "        branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 224, [1, 3], name=name_fmt('Conv2d_0b_1x3', 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 256, [3, 1], name=name_fmt('Conv2d_0c_3x1', 1))\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"Block35\", \"Block17\" or \"Block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    mixed = Concatenate(axis=channel_axis, name=name_fmt('Concatenate'))(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                   K.int_shape(x)[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=name_fmt('Conv2d_1x1'))\n",
    "    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "               output_shape=K.int_shape(x)[1:],\n",
    "               arguments={'scale': scale},\n",
    "               name=name_fmt('ScaleSum'))([x, up])\n",
    "    if activation is not None:\n",
    "        x = Activation(activation, name=name_fmt('Activation'))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionResNetV2(include_top=True,\n",
    "                      weights='imagenet',\n",
    "                      input_tensor=None,\n",
    "                      input_shape=None,\n",
    "                      pooling=None,\n",
    "                      classes=1000,\n",
    "                      dropout_keep_prob=0.8):\n",
    "  \n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Stem block: 35 x 35 x 192\n",
    "    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid', name='Conv2d_1a_3x3')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid', name='Conv2d_2a_3x3')\n",
    "    x = conv2d_bn(x, 64, 3, name='Conv2d_2b_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid', name='Conv2d_3b_1x1')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid', name='Conv2d_4a_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_5a_3x3')(x)\n",
    "\n",
    "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_5b')\n",
    "    branch_0 = conv2d_bn(x, 96, 1, name=name_fmt('Conv2d_1x1', 0))\n",
    "    branch_1 = conv2d_bn(x, 48, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 5, name=name_fmt('Conv2d_0b_5x5', 1))\n",
    "    branch_2 = conv2d_bn(x, 64, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, name=name_fmt('Conv2d_0c_3x3', 2))\n",
    "    branch_pool = AveragePooling2D(3,\n",
    "                                   strides=1,\n",
    "                                   padding='same',\n",
    "                                   name=name_fmt('AvgPool_0a_3x3', 3))(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, name=name_fmt('Conv2d_0b_1x1', 3))\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_5b')(branches)\n",
    "\n",
    "    # 10x Block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
    "    for block_idx in range(1, 11):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.17,\n",
    "                                    block_type='Block35',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_6a')\n",
    "    branch_0 = conv2d_bn(x,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 2))(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_6a')(branches)\n",
    "\n",
    "    # 20x Block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
    "    for block_idx in range(1, 21):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.1,\n",
    "                                    block_type='Block17',\n",
    "                                    block_idx=block_idx)\n",
    "\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    name_fmt = partial(_generate_layer_name, prefix='Mixed_7a')\n",
    "    branch_0 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 0))\n",
    "    branch_0 = conv2d_bn(branch_0,\n",
    "                         384,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 0))\n",
    "    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n",
    "    branch_1 = conv2d_bn(branch_1,\n",
    "                         288,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 1))\n",
    "    branch_2 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n",
    "    branch_2 = conv2d_bn(branch_2, 288, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n",
    "    branch_2 = conv2d_bn(branch_2,\n",
    "                         320,\n",
    "                         3,\n",
    "                         strides=2,\n",
    "                         padding='valid',\n",
    "                         name=name_fmt('Conv2d_1a_3x3', 2))\n",
    "    branch_pool = MaxPooling2D(3,\n",
    "                               strides=2,\n",
    "                               padding='valid',\n",
    "                               name=name_fmt('MaxPool_1a_3x3', 3))(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='Mixed_7a')(branches)\n",
    "\n",
    "    # 10x Block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
    "    for block_idx in range(1, 10):\n",
    "        x = _inception_resnet_block(x,\n",
    "                                    scale=0.2,\n",
    "                                    block_type='Block8',\n",
    "                                    block_idx=block_idx)\n",
    "    x = _inception_resnet_block(x,\n",
    "                                scale=1.,\n",
    "                                activation=None,\n",
    "                                block_type='Block8',\n",
    "                                block_idx=10)\n",
    "\n",
    "    # Final convolution block\n",
    "    x = conv2d_bn(x, 1536, 1, name='Conv2d_7b_1x1')\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "        x = Dropout(1.0 - dropout_keep_prob, name='Dropout')(x)\n",
    "        x = Dense(classes, name='Logits')(x)\n",
    "        x = Activation('softmax', name='Predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D(name='MaxPool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`\n",
    "    if input_tensor is not None:\n",
    "        inputs = tf.keras.utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs, x, name='inception_resnet_v2')\n",
    "\n",
    "    # Load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "        if include_top:\n",
    "            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "            weights_path = get_file(weights_filename,\n",
    "                                    BASE_WEIGHT_URL + weights_filename,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='e693bd0210a403b3192acc6073ad2e96')\n",
    "        else:\n",
    "            weights_filename = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "            weights_path = get_file(weights_filename,\n",
    "                                    BASE_WEIGHT_URL + weights_filename,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='d19885ff4a710c122648d3b5c3b684e4')\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6841645a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:01:34.999792Z",
     "iopub.status.busy": "2021-12-28T23:01:34.999008Z",
     "iopub.status.idle": "2021-12-28T23:01:53.390997Z",
     "shell.execute_reply": "2021-12-28T23:01:53.390294Z",
     "shell.execute_reply.started": "2021-12-28T19:01:47.334603Z"
    },
    "papermill": {
     "duration": 18.427154,
     "end_time": "2021-12-28T23:01:53.391153",
     "exception": false,
     "start_time": "2021-12-28T23:01:34.963999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-28 23:01:35.103509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:35.224955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:35.226149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:35.227953: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-28 23:01:35.229312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:35.230353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:35.231337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:37.283114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:37.284314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:37.285333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-28 23:01:37.286342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/myutwo150/keras-inception-resnet-v2/releases/download/v0.1/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 9s 0us/step\n",
      "219070464/219055592 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = InceptionResNetV2(include_top=False,\n",
    "                      weights='imagenet',\n",
    "                      input_shape=(224,224,3),\n",
    "                      pooling=None,\n",
    "                      classes=1000,\n",
    "                      dropout_keep_prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884c518d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:01:53.531819Z",
     "iopub.status.busy": "2021-12-28T23:01:53.530727Z",
     "iopub.status.idle": "2021-12-28T23:01:53.606804Z",
     "shell.execute_reply": "2021-12-28T23:01:53.605950Z",
     "shell.execute_reply.started": "2021-12-28T19:02:24.903391Z"
    },
    "papermill": {
     "duration": 0.145271,
     "end_time": "2021-12-28T23:01:53.606980",
     "exception": false,
     "start_time": "2021-12-28T23:01:53.461709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472684a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:01:53.762261Z",
     "iopub.status.busy": "2021-12-28T23:01:53.752607Z",
     "iopub.status.idle": "2021-12-28T23:37:39.234252Z",
     "shell.execute_reply": "2021-12-28T23:37:39.233299Z",
     "shell.execute_reply.started": "2021-12-28T19:02:24.986253Z"
    },
    "papermill": {
     "duration": 2145.561431,
     "end_time": "2021-12-28T23:37:39.234420",
     "exception": false,
     "start_time": "2021-12-28T23:01:53.672989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-28 23:01:53.776747: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2051245056 exceeds 10% of free system memory.\n",
      "2021-12-28 23:01:55.793628: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2051245056 exceeds 10% of free system memory.\n",
      "2021-12-28 23:01:57.464912: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-28 23:02:18.533434: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 182s 362ms/step - loss: 0.4621 - accuracy: 0.8492 - val_loss: 1.2292 - val_accuracy: 0.6943\n",
      "Epoch 2/14\n",
      "426/426 [==============================] - 148s 348ms/step - loss: 0.3116 - accuracy: 0.8951 - val_loss: 0.2392 - val_accuracy: 0.9160\n",
      "Epoch 3/14\n",
      "426/426 [==============================] - 148s 346ms/step - loss: 0.2596 - accuracy: 0.9121 - val_loss: 0.7206 - val_accuracy: 0.8020\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 4/14\n",
      "426/426 [==============================] - 148s 347ms/step - loss: 0.1481 - accuracy: 0.9483 - val_loss: 0.0871 - val_accuracy: 0.9707\n",
      "Epoch 5/14\n",
      "426/426 [==============================] - 148s 348ms/step - loss: 0.1067 - accuracy: 0.9621 - val_loss: 0.0438 - val_accuracy: 0.9867\n",
      "Epoch 6/14\n",
      "426/426 [==============================] - 150s 352ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.0572 - val_accuracy: 0.9763\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 7/14\n",
      "426/426 [==============================] - 149s 349ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.0085 - val_accuracy: 0.9990\n",
      "Epoch 8/14\n",
      "426/426 [==============================] - 148s 347ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 9/14\n",
      "426/426 [==============================] - 148s 348ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/14\n",
      "426/426 [==============================] - 148s 348ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 11/14\n",
      "426/426 [==============================] - 149s 350ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 12/14\n",
      "426/426 [==============================] - 149s 351ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 13/14\n",
      "426/426 [==============================] - 150s 353ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
      "Epoch 14/14\n",
      "426/426 [==============================] - 149s 350ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0012 - val_accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "init_time = datetime.datetime.now()\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "\n",
    "trained = model.fit(\n",
    "                    train_images, train_labels,\n",
    "                    validation_data = (val_images, val_labels),\n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    epochs=14,\n",
    "                    callbacks=[learning_rate_reduction]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc114bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:37:43.700761Z",
     "iopub.status.busy": "2021-12-28T23:37:43.694330Z",
     "iopub.status.idle": "2021-12-28T23:37:47.110447Z",
     "shell.execute_reply": "2021-12-28T23:37:47.111340Z",
     "shell.execute_reply.started": "2021-12-28T20:04:11.379334Z"
    },
    "papermill": {
     "duration": 5.64307,
     "end_time": "2021-12-28T23:37:47.111689",
     "exception": false,
     "start_time": "2021-12-28T23:37:41.468619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('modelincenAet1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf7e369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:37:51.736959Z",
     "iopub.status.busy": "2021-12-28T23:37:51.734219Z",
     "iopub.status.idle": "2021-12-28T23:37:51.739422Z",
     "shell.execute_reply": "2021-12-28T23:37:51.739992Z",
     "shell.execute_reply.started": "2021-12-28T19:39:10.309407Z"
    },
    "papermill": {
     "duration": 2.647687,
     "end_time": "2021-12-28T23:37:51.740160",
     "exception": false,
     "start_time": "2021-12-28T23:37:49.092473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = (\n",
    "    'https://github.com/fchollet/deep-learning-models/'\n",
    "    'releases/download/v0.5/'\n",
    "    'inception_v3_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "WEIGHTS_PATH_NO_TOP = (\n",
    "    'https://github.com/fchollet/deep-learning-models/'\n",
    "    'releases/download/v0.5/'\n",
    "    'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "def load_weights(model,weights,include_top):\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path =  tf.keras.utils.get_file(\n",
    "                'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n",
    "        else:\n",
    "            weights_path =  tf.keras.utils.get_file(\n",
    "                'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def makelayer(x,filters,num_row,num_col,padding='same',strides=(1, 1),name=None):\n",
    "\n",
    "   \n",
    "    if image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(filters, (num_row, num_col),strides=strides,padding=padding,use_bias=False,name=name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "def blockA(x,unique_filters,concat_axis,name=None):\n",
    "    branch1x1 = makelayer(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = makelayer(x, 48, 1, 1)\n",
    "    branch5x5 = makelayer(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = makelayer(x, 64, 1, 1)\n",
    "    branch3x3dbl = makelayer(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = makelayer(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3),\n",
    "                                          strides=(1, 1),\n",
    "                                          padding='same')(x)\n",
    "    branch_pool = makelayer(branch_pool, unique_filters, 1, 1)\n",
    "    x = concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=concat_axis,\n",
    "        name='mixed'+name)\n",
    "    return x\n",
    "\n",
    "def blockB(x,unique_filters,concat_axis,name=None):\n",
    "    branch1x1 = makelayer(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = makelayer(x, unique_filters, 1, 1)\n",
    "    branch7x7 = makelayer(branch7x7, unique_filters, 1, 7)\n",
    "    branch7x7 = makelayer(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = makelayer(x, unique_filters, 1, 1)\n",
    "    branch7x7dbl = makelayer(branch7x7dbl, unique_filters, 7, 1)\n",
    "    branch7x7dbl = makelayer(branch7x7dbl, unique_filters, 1, 7)\n",
    "    branch7x7dbl = makelayer(branch7x7dbl, unique_filters, 7, 1)\n",
    "    branch7x7dbl = makelayer(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = makelayer(branch_pool, 192, 1, 1)\n",
    "    x = concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=concat_axis,\n",
    "        name='mixed' + name)\n",
    "    return x\n",
    "\n",
    "def blockC(x,concat_axis,name=None):\n",
    "    branch1x1 = makelayer(x, 320, 1, 1)\n",
    "\n",
    "    branch3x3 = makelayer(x, 384, 1, 1)\n",
    "    branch3x3_1 = makelayer(branch3x3, 384, 1, 3)\n",
    "    branch3x3_2 = makelayer(branch3x3, 384, 3, 1)\n",
    "    branch3x3 = concatenate(\n",
    "        [branch3x3_1, branch3x3_2],\n",
    "        axis=concat_axis,\n",
    "        name='mixed9_' + name)\n",
    "\n",
    "    branch3x3dbl = makelayer(x, 448, 1, 1)\n",
    "    branch3x3dbl = makelayer(branch3x3dbl, 384, 3, 3)\n",
    "    branch3x3dbl_1 = makelayer(branch3x3dbl, 384, 1, 3)\n",
    "    branch3x3dbl_2 = makelayer(branch3x3dbl, 384, 3, 1)\n",
    "    branch3x3dbl = concatenate(\n",
    "        [branch3x3dbl_1, branch3x3dbl_2], axis=concat_axis)\n",
    "\n",
    "    branch_pool = AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = makelayer(branch_pool, 192, 1, 1)\n",
    "    x = concatenate(\n",
    "        [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "        axis=concat_axis,\n",
    "        name='mixed' + str(9 + int(name)))\n",
    "    return x\n",
    "def auxiliary_classifier(x,num_classes):\n",
    "    x1 = AveragePooling2D((5,5),strides=(3,3))(x)\n",
    "    x1 = makelayer(x1, 128,1,1)\n",
    "    x1 = Dense(1000, activation='softmax',name='auxillary_classifier')(x1)\n",
    "    return x1\n",
    "def InceptionV3(include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000,\n",
    "                **kwargs):\n",
    "\n",
    "    \n",
    "    img_input = input_tensor\n",
    "\n",
    "    if image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = makelayer(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = makelayer(x, 32, 3, 3, padding='valid')\n",
    "    x = makelayer(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = makelayer(x, 80, 1, 1, padding='valid')\n",
    "    x = makelayer(x, 192, 3, 3, padding='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    #blockA divide 5x5 con to 2*(3X3)\n",
    "    x = blockA(x,32,channel_axis,\"0\")\n",
    "    x = blockA(x,64,channel_axis,\"1\")\n",
    "    x = blockA(x,64,channel_axis,\"2\")\n",
    "\n",
    "\n",
    "   \n",
    "    branch3x3 = makelayer(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = makelayer(x, 64, 1, 1)\n",
    "    branch3x3dbl = makelayer(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = makelayer(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed3')\n",
    "    #blockB divide 7X7 to 2 asym 1X7,7X1\n",
    "\n",
    "    x = blockB(x,128,channel_axis,\"4\")\n",
    "    x = blockB(x,160,channel_axis,\"5\")\n",
    "    x = blockB(x,160,channel_axis,\"6\")\n",
    "    x =blockB(x,192,channel_axis,\"7\")\n",
    "\n",
    "\n",
    "    x1 = auxiliary_classifier(x,classes)\n",
    "\n",
    " \n",
    "    branch3x3 = makelayer(x, 192, 1, 1)\n",
    "    branch3x3 = makelayer(branch3x3, 320, 3, 3,\n",
    "                          strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = makelayer(x, 192, 1, 1)\n",
    "    branch7x7x3 = makelayer(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = makelayer(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = makelayer(\n",
    "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = concatenate(\n",
    "        [branch3x3, branch7x7x3, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed8')\n",
    "\n",
    "    #blockC divide 3X3 to 2 asym 1X3,3X1\n",
    "    x = blockC(x,channel_axis,\"1\")\n",
    "    x = blockC(x,channel_axis,\"2\")\n",
    "\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = tf.keras.utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    \n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='inception_v3')\n",
    "\n",
    "    # Load weights.\n",
    "    model = load_weights(model,weights,include_top)\n",
    "    print(\"Inception v3 model created\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "868fce66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:37:56.811256Z",
     "iopub.status.busy": "2021-12-28T23:37:56.810151Z",
     "iopub.status.idle": "2021-12-28T23:38:01.769444Z",
     "shell.execute_reply": "2021-12-28T23:38:01.770286Z",
     "shell.execute_reply.started": "2021-12-28T19:39:15.445980Z"
    },
    "papermill": {
     "duration": 7.140864,
     "end_time": "2021-12-28T23:38:01.770601",
     "exception": false,
     "start_time": "2021-12-28T23:37:54.629737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 2s 0us/step\n",
      "87924736/87910968 [==============================] - 2s 0us/step\n",
      "Inception v3 model created\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "model2 = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4194967e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:38:06.255047Z",
     "iopub.status.busy": "2021-12-28T23:38:06.252507Z",
     "iopub.status.idle": "2021-12-28T23:38:06.278534Z",
     "shell.execute_reply": "2021-12-28T23:38:06.278025Z",
     "shell.execute_reply.started": "2021-12-28T19:39:30.646284Z"
    },
    "papermill": {
     "duration": 2.050661,
     "end_time": "2021-12-28T23:38:06.278741",
     "exception": false,
     "start_time": "2021-12-28T23:38:04.228080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = model2.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(6, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8dd603f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:38:10.291496Z",
     "iopub.status.busy": "2021-12-28T23:38:10.290485Z",
     "iopub.status.idle": "2021-12-28T23:55:43.359098Z",
     "shell.execute_reply": "2021-12-28T23:55:43.359631Z",
     "shell.execute_reply.started": "2021-12-28T19:40:00.828970Z"
    },
    "papermill": {
     "duration": 1055.095191,
     "end_time": "2021-12-28T23:55:43.359916",
     "exception": false,
     "start_time": "2021-12-28T23:38:08.264725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-28 23:38:10.323339: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2051245056 exceeds 10% of free system memory.\n",
      "2021-12-28 23:38:12.401830: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2051245056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "426/426 [==============================] - 77s 162ms/step - loss: 0.5702 - accuracy: 0.8160 - val_loss: 0.9231 - val_accuracy: 0.7020\n",
      "Epoch 2/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.3761 - accuracy: 0.8708 - val_loss: 0.3963 - val_accuracy: 0.8657\n",
      "Epoch 3/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.3153 - accuracy: 0.8930 - val_loss: 1.3865 - val_accuracy: 0.7507\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 4/15\n",
      "426/426 [==============================] - 65s 152ms/step - loss: 0.1907 - accuracy: 0.9319 - val_loss: 0.1106 - val_accuracy: 0.9610\n",
      "Epoch 5/15\n",
      "426/426 [==============================] - 66s 154ms/step - loss: 0.1425 - accuracy: 0.9504 - val_loss: 0.1763 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 6/15\n",
      "426/426 [==============================] - 65s 152ms/step - loss: 0.0797 - accuracy: 0.9731 - val_loss: 0.0253 - val_accuracy: 0.9950\n",
      "Epoch 7/15\n",
      "426/426 [==============================] - 65s 154ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 0.0142 - val_accuracy: 0.9980\n",
      "Epoch 8/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 9/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 10/15\n",
      "426/426 [==============================] - 66s 154ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
      "Epoch 11/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 12/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 13/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 14/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
      "Epoch 15/15\n",
      "426/426 [==============================] - 65s 153ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0014 - val_accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=model2.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# compile the model (should be done after setting layers to non-trainable)\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "init_time = datetime.datetime.now()\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "\n",
    "trained = model2.fit(\n",
    "                    train_images, train_labels,\n",
    "                    validation_data = (val_images, val_labels),\n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    epochs=15,\n",
    "                    callbacks=[learning_rate_reduction]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252aba56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:55:51.728169Z",
     "iopub.status.busy": "2021-12-28T23:55:51.727144Z",
     "iopub.status.idle": "2021-12-28T23:55:53.943650Z",
     "shell.execute_reply": "2021-12-28T23:55:53.944479Z",
     "shell.execute_reply.started": "2021-12-28T20:04:46.121999Z"
    },
    "papermill": {
     "duration": 6.564875,
     "end_time": "2021-12-28T23:55:53.944680",
     "exception": false,
     "start_time": "2021-12-28T23:55:47.379805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.save('inceptionv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2292514e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:56:02.552991Z",
     "iopub.status.busy": "2021-12-28T23:56:02.552157Z",
     "iopub.status.idle": "2021-12-28T23:56:02.828462Z",
     "shell.execute_reply": "2021-12-28T23:56:02.829298Z",
     "shell.execute_reply.started": "2021-12-28T20:07:43.614927Z"
    },
    "papermill": {
     "duration": 4.725982,
     "end_time": "2021-12-28T23:56:02.829551",
     "exception": false,
     "start_time": "2021-12-28T23:55:58.103569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample:  3000 {'glacier': 553, 'mountain': 525, 'sea': 510, 'street': 501, 'forest': 474, 'buildings': 437}\n"
     ]
    }
   ],
   "source": [
    "CLASSES = {'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5, 'forest': 1, 'buildings': 0}\n",
    "filenames = tf.io.gfile.glob('/kaggle/input/intel-image-classification/seg_test/seg_test/*/*')\n",
    "image_path_df_test = pd.DataFrame(data={'filename': filenames, 'class': [x.split('/')[-2] for x in filenames]})\n",
    "\n",
    "print('Test sample: ', len(image_path_df_test['class']), dict(image_path_df_test['class'].value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1e3686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:56:11.033078Z",
     "iopub.status.busy": "2021-12-28T23:56:11.032328Z",
     "iopub.status.idle": "2021-12-28T23:56:11.036769Z",
     "shell.execute_reply": "2021-12-28T23:56:11.036200Z",
     "shell.execute_reply.started": "2021-12-28T20:07:45.358698Z"
    },
    "papermill": {
     "duration": 4.156645,
     "end_time": "2021-12-28T23:56:11.036933",
     "exception": false,
     "start_time": "2021-12-28T23:56:06.880288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shuffle_prune(df, BATCH_SIZE):\n",
    "    df = shuffle(df, random_state=42)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df[ : df.shape[0] // BATCH_SIZE * BATCH_SIZE]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "031d1b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:56:19.592548Z",
     "iopub.status.busy": "2021-12-28T23:56:19.591598Z",
     "iopub.status.idle": "2021-12-28T23:56:19.605762Z",
     "shell.execute_reply": "2021-12-28T23:56:19.606525Z",
     "shell.execute_reply.started": "2021-12-28T20:07:50.850394Z"
    },
    "papermill": {
     "duration": 4.119368,
     "end_time": "2021-12-28T23:56:19.606785",
     "exception": false,
     "start_time": "2021-12-28T23:56:15.487417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample:  1472 {2: 271, 3: 259, 4: 250, 5: 246, 1: 235, 0: 211}\n"
     ]
    }
   ],
   "source": [
    "image_path_df_test, image_path_df_val1  = train_test_split(image_path_df_test, test_size=0.5, random_state=42, stratify=image_path_df_test['class'])\n",
    "image_path_df_test = shuffle_prune(image_path_df_test, BATCH_SIZE)\n",
    "image_path_df_test['class'] = image_path_df_test['class'].map(CLASSES)\n",
    "\n",
    "# image_path_df_val = shuffle_prune(image_path_df_val, BATCH_SIZE)\n",
    "# image_path_df_val['class'] = image_path_df_val['class'].map(CLASSES)\n",
    "\n",
    "print('Test sample: ', len(image_path_df_test['class']), dict(image_path_df_test['class'].value_counts()))\n",
    "# print('Val  sample: ', len(image_path_df_val['class']), dict(image_path_df_val['class'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f535d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:56:29.007074Z",
     "iopub.status.busy": "2021-12-28T23:56:29.006083Z",
     "iopub.status.idle": "2021-12-28T23:56:38.163006Z",
     "shell.execute_reply": "2021-12-28T23:56:38.162098Z",
     "shell.execute_reply.started": "2021-12-28T20:07:55.516082Z"
    },
    "papermill": {
     "duration": 13.832936,
     "end_time": "2021-12-28T23:56:38.163247",
     "exception": false,
     "start_time": "2021-12-28T23:56:24.330311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set: (1472, 224, 224, 3)\n",
      "Shape of test set: (1472,)\n"
     ]
    }
   ],
   "source": [
    "# val_images, val_labels = get_images_and_labels_arrays(image_path_df_val)\n",
    "\n",
    "# print(f'Shape of validation set: {val_images.shape}')\n",
    "# print(f'Shape of validation set: {val_labels.shape}')\n",
    "test_images, test_labels = labele_image(image_path_df_test)\n",
    "test_images=np.array(test_images)\n",
    "print(f'Shape of test set: {test_images.shape}')\n",
    "print(f'Shape of test set: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4516fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:56:46.936874Z",
     "iopub.status.busy": "2021-12-28T23:56:46.900749Z",
     "iopub.status.idle": "2021-12-28T23:57:00.963466Z",
     "shell.execute_reply": "2021-12-28T23:57:00.962477Z",
     "shell.execute_reply.started": "2021-12-28T20:10:17.154664Z"
    },
    "papermill": {
     "duration": 18.54659,
     "end_time": "2021-12-28T23:57:00.963697",
     "exception": false,
     "start_time": "2021-12-28T23:56:42.417107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "keras_model = tf.keras.models.load_model('./modelincenAet1.h5', compile=False)\n",
    "keras_model._name = 'modelincenet.h5'\n",
    "keras_model2 = tf.keras.models.load_model('./inceptionv3.h5', compile=False)\n",
    "keras_model2._name = 'modelincev3'\n",
    "models = [keras_model, keras_model2]\n",
    "#model_input = tf.keras.Input(shape=(125, 125, 3))\n",
    "model_input = tf.keras.Input(shape=(224, 224, 3))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
    "ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)  \n",
    "\n",
    "ensemble_model.save('ensemble.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a00f709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:57:09.573182Z",
     "iopub.status.busy": "2021-12-28T23:57:09.572108Z",
     "iopub.status.idle": "2021-12-28T23:57:29.017290Z",
     "shell.execute_reply": "2021-12-28T23:57:29.017839Z",
     "shell.execute_reply.started": "2021-12-28T20:11:49.119583Z"
    },
    "papermill": {
     "duration": 23.871032,
     "end_time": "2021-12-28T23:57:29.018155",
     "exception": false,
     "start_time": "2021-12-28T23:57:05.147123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9864130616188049   loss:  0.044471465051174164\n"
     ]
    }
   ],
   "source": [
    "ensemble_model.compile(optimizer='adam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "test_loss, test_acc = ensemble_model.evaluate(test_images, test_labels , verbose=0)\n",
    "print('\\naccuracy:', test_acc, '  loss: ',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21fd22dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:57:38.199780Z",
     "iopub.status.busy": "2021-12-28T23:57:38.199046Z",
     "iopub.status.idle": "2021-12-28T23:57:39.091882Z",
     "shell.execute_reply": "2021-12-28T23:57:39.092427Z",
     "shell.execute_reply.started": "2021-12-28T20:13:54.896443Z"
    },
    "papermill": {
     "duration": 5.01008,
     "end_time": "2021-12-28T23:57:39.092637",
     "exception": false,
     "start_time": "2021-12-28T23:57:34.082557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number filenames: 3407\n"
     ]
    }
   ],
   "source": [
    "filenames = tf.io.gfile.glob('../input/ci-sc22-places-and-scene-recognition/test_images/test_images/*')\n",
    "\n",
    "image_path_df_predict = pd.DataFrame(data={\"filename\":filenames ,'imgname':  [x.split('/')[-1] for x in filenames], 'class': np.nan})\n",
    "print(f'Number filenames: {len(image_path_df_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79b83a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:57:47.844786Z",
     "iopub.status.busy": "2021-12-28T23:57:47.844127Z",
     "iopub.status.idle": "2021-12-28T23:58:10.217559Z",
     "shell.execute_reply": "2021-12-28T23:58:10.216777Z",
     "shell.execute_reply.started": "2021-12-28T20:14:14.992502Z"
    },
    "papermill": {
     "duration": 26.573718,
     "end_time": "2021-12-28T23:58:10.217777",
     "exception": false,
     "start_time": "2021-12-28T23:57:43.644059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images set to prediction: (3407, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "to_predict_images, to_predict_labels = labele_image(image_path_df_predict)\n",
    "to_predict_images=np.array(to_predict_images)\n",
    "\n",
    "print(f'Shape of images set to prediction: {to_predict_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9374f47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:58:18.844928Z",
     "iopub.status.busy": "2021-12-28T23:58:18.843812Z",
     "iopub.status.idle": "2021-12-28T23:58:45.462321Z",
     "shell.execute_reply": "2021-12-28T23:58:45.461783Z",
     "shell.execute_reply.started": "2021-12-28T20:14:31.460678Z"
    },
    "papermill": {
     "duration": 30.777464,
     "end_time": "2021-12-28T23:58:45.462472",
     "exception": false,
     "start_time": "2021-12-28T23:58:14.685008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 1, 1, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = np.argmax(ensemble_model.predict(to_predict_images), axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38fe377d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:58:54.065486Z",
     "iopub.status.busy": "2021-12-28T23:58:54.064475Z",
     "iopub.status.idle": "2021-12-28T23:58:54.095602Z",
     "shell.execute_reply": "2021-12-28T23:58:54.095044Z",
     "shell.execute_reply.started": "2021-12-28T20:15:16.984950Z"
    },
    "papermill": {
     "duration": 4.227474,
     "end_time": "2021-12-28T23:58:54.095752",
     "exception": false,
     "start_time": "2021-12-28T23:58:49.868278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "row = []\n",
    "fields = ['image_name', 'label']\n",
    "for i in range(len(predict)):\n",
    "    row .append([image_path_df_predict['imgname'][i],predict[i]])\n",
    "with open('sample_submission5555.csv', 'w') as f:\n",
    "    write = csv.writer(f)   \n",
    "    write.writerow(fields)\n",
    "    write.writerows(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d3c101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:59:02.777488Z",
     "iopub.status.busy": "2021-12-28T23:59:02.775595Z",
     "iopub.status.idle": "2021-12-28T23:59:02.780518Z",
     "shell.execute_reply": "2021-12-28T23:59:02.780040Z",
     "shell.execute_reply.started": "2021-12-28T21:42:21.431576Z"
    },
    "papermill": {
     "duration": 4.184532,
     "end_time": "2021-12-28T23:59:02.780689",
     "exception": false,
     "start_time": "2021-12-28T23:58:58.596157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# from __future__ import print_function\n",
    "# from __future__ import absolute_import\n",
    "\n",
    "# import warnings\n",
    "# import numpy as np\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras import layers\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import BatchNormalization\n",
    "# from keras.layers import Activation\n",
    "# from keras.layers import Conv2D\n",
    "# from keras.layers import SeparableConv2D\n",
    "# from keras.layers import MaxPooling2D\n",
    "# from keras.layers import GlobalAveragePooling2D\n",
    "# from keras.layers import GlobalMaxPooling2D\n",
    "# from keras.utils.data_utils import get_file\n",
    "# from keras import backend as K\n",
    "# from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "\n",
    "\n",
    "# TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "# TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "# def Xception(include_top=True, weights='imagenet',\n",
    "#              input_tensor=None, input_shape=None,\n",
    "#              pooling=None,\n",
    "#              classes=1000):\n",
    "#     \"\"\"Instantiates the Xception architecture.\n",
    "#     Optionally loads weights pre-trained\n",
    "#     on ImageNet. This model is available for TensorFlow only,\n",
    "#     and can only be used with inputs following the TensorFlow\n",
    "#     data format `(width, height, channels)`.\n",
    "#     You should set `image_data_format=\"channels_last\"` in your Keras config\n",
    "#     located at ~/.keras/keras.json.\n",
    "#     Note that the default input image size for this model is 299x299.\n",
    "#     # Arguments\n",
    "#         include_top: whether to include the fully-connected\n",
    "#             layer at the top of the network.\n",
    "#         weights: one of `None` (random initialization)\n",
    "#             or \"imagenet\" (pre-training on ImageNet).\n",
    "#         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "#             to use as image input for the model.\n",
    "#         input_shape: optional shape tuple, only to be specified\n",
    "#             if `include_top` is False (otherwise the input shape\n",
    "#             has to be `(299, 299, 3)`.\n",
    "#             It should have exactly 3 inputs channels,\n",
    "#             and width and height should be no smaller than 71.\n",
    "#             E.g. `(150, 150, 3)` would be one valid value.\n",
    "#         pooling: Optional pooling mode for feature extraction\n",
    "#             when `include_top` is `False`.\n",
    "#             - `None` means that the output of the model will be\n",
    "#                 the 4D tensor output of the\n",
    "#                 last convolutional layer.\n",
    "#             - `avg` means that global average pooling\n",
    "#                 will be applied to the output of the\n",
    "#                 last convolutional layer, and thus\n",
    "#                 the output of the model will be a 2D tensor.\n",
    "#             - `max` means that global max pooling will\n",
    "#                 be applied.\n",
    "#         classes: optional number of classes to classify images\n",
    "#             into, only to be specified if `include_top` is True, and\n",
    "#             if no `weights` argument is specified.\n",
    "#     # Returns\n",
    "#         A Keras model instance.\n",
    "#     # Raises\n",
    "#         ValueError: in case of invalid argument for `weights`,\n",
    "#             or invalid input shape.\n",
    "#         RuntimeError: If attempting to run this model with a\n",
    "#             backend that does not support separable convolutions.\n",
    "#     \"\"\"\n",
    "#     if weights not in {'imagenet', None}:\n",
    "#         raise ValueError('The `weights` argument should be either '\n",
    "#                          '`None` (random initialization) or `imagenet` '\n",
    "#                          '(pre-training on ImageNet).')\n",
    "\n",
    "#     if weights == 'imagenet' and include_top and classes != 1000:\n",
    "#         raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "#                          ' as true, `classes` should be 1000')\n",
    "\n",
    "#     if K.backend() != 'tensorflow':\n",
    "#         raise RuntimeError('The Xception model is only available with '\n",
    "#                            'the TensorFlow backend.')\n",
    "#     if K.image_data_format() != 'channels_last':\n",
    "#         warnings.warn('The Xception model is only available for the '\n",
    "#                       'input data format \"channels_last\" '\n",
    "#                       '(width, height, channels). '\n",
    "#                       'However your settings specify the default '\n",
    "#                       'data format \"channels_first\" (channels, width, height). '\n",
    "#                       'You should set `image_data_format=\"channels_last\"` in your Keras '\n",
    "#                       'config located at ~/.keras/keras.json. '\n",
    "#                       'The model being returned right now will expect inputs '\n",
    "#                       'to follow the \"channels_last\" data format.')\n",
    "#         K.set_image_data_format('channels_last')\n",
    "#         old_data_format = 'channels_first'\n",
    "#     else:\n",
    "#         old_data_format = None\n",
    "\n",
    "#     # Determine proper input shape\n",
    "# #     input_shape = _obtain_input_shape(input_shape,\n",
    "# #                                       default_size=299,\n",
    "# #                                       min_size=71,\n",
    "# #                                       data_format=K.image_data_format(),\n",
    "# #                                       include_top=include_top)\n",
    "\n",
    "#     if input_tensor is None:\n",
    "#         img_input = Input(shape=input_shape)\n",
    "#     else:\n",
    "#         if not K.is_keras_tensor(input_tensor):\n",
    "#             img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "#         else:\n",
    "#             img_input = input_tensor\n",
    "\n",
    "#     x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)\n",
    "#     x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "#     x = Activation('relu', name='block1_conv1_act')(x)\n",
    "#     x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
    "#     x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "#     x = Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "#     residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "#                       padding='same', use_bias=False)(x)\n",
    "#     residual = BatchNormalization()(residual)\n",
    "\n",
    "#     x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n",
    "#     x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "#     x = Activation('relu', name='block2_sepconv2_act')(x)\n",
    "#     x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)\n",
    "#     x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "#     x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n",
    "#     x = layers.add([x, residual])\n",
    "\n",
    "#     residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
    "#                       padding='same', use_bias=False)(x)\n",
    "#     residual = BatchNormalization()(residual)\n",
    "\n",
    "#     x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "#     x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n",
    "#     x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "#     x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "#     x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n",
    "#     x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "\n",
    "#     x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n",
    "#     x = layers.add([x, residual])\n",
    "\n",
    "#     residual = Conv2D(728, (1, 1), strides=(2, 2),\n",
    "#                       padding='same', use_bias=False)(x)\n",
    "#     residual = BatchNormalization()(residual)\n",
    "\n",
    "#     x = Activation('relu', name='block4_sepconv1_act')(x)\n",
    "#     x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n",
    "#     x = BatchNormalization(name='block4_sepconv1_bn')(x)\n",
    "#     x = Activation('relu', name='block4_sepconv2_act')(x)\n",
    "#     x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n",
    "#     x = BatchNormalization(name='block4_sepconv2_bn')(x)\n",
    "\n",
    "#     x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n",
    "#     x = layers.add([x, residual])\n",
    "\n",
    "#     for i in range(8):\n",
    "#         residual = x\n",
    "#         prefix = 'block' + str(i + 5)\n",
    "\n",
    "#         x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "#         x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n",
    "#         x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
    "#         x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "#         x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n",
    "#         x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
    "#         x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "#         x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n",
    "#         x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
    "\n",
    "#         x = layers.add([x, residual])\n",
    "\n",
    "#     residual = Conv2D(1024, (1, 1), strides=(2, 2),\n",
    "#                       padding='same', use_bias=False)(x)\n",
    "#     residual = BatchNormalization()(residual)\n",
    "\n",
    "#     x = Activation('relu', name='block13_sepconv1_act')(x)\n",
    "#     x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)\n",
    "#     x = BatchNormalization(name='block13_sepconv1_bn')(x)\n",
    "#     x = Activation('relu', name='block13_sepconv2_act')(x)\n",
    "#     x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)\n",
    "#     x = BatchNormalization(name='block13_sepconv2_bn')(x)\n",
    "\n",
    "#     x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n",
    "#     x = layers.add([x, residual])\n",
    "\n",
    "#     x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)\n",
    "#     x = BatchNormalization(name='block14_sepconv1_bn')(x)\n",
    "#     x = Activation('relu', name='block14_sepconv1_act')(x)\n",
    "\n",
    "#     x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
    "#     x = BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "#     x = Activation('relu', name='block14_sepconv2_act')(x)\n",
    "\n",
    "#     if include_top:\n",
    "#         x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "#         x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "#     else:\n",
    "#         if pooling == 'avg':\n",
    "#             x = GlobalAveragePooling2D()(x)\n",
    "#         elif pooling == 'max':\n",
    "#             x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "#     # Ensure that the model takes into account\n",
    "#     # any potential predecessors of `input_tensor`.\n",
    "#     if input_tensor is not None:\n",
    "#         inputs = tf.keras.utils.get_source_inputs(input_tensor)\n",
    "#     else:\n",
    "#         inputs = img_input\n",
    "#     # Create model.\n",
    "#     model = Model(inputs, x, name='xception')\n",
    "\n",
    "#     # load weights\n",
    "#     if weights == 'imagenet':\n",
    "#         if include_top:\n",
    "#             weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "#                                     TF_WEIGHTS_PATH,\n",
    "#                                     cache_subdir='models')\n",
    "#         else:\n",
    "#             weights_path = get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "#                                     TF_WEIGHTS_PATH_NO_TOP,\n",
    "#                                     cache_subdir='models')\n",
    "#         model.load_weights(weights_path)\n",
    "\n",
    "#     if old_data_format:\n",
    "#         K.set_image_data_format(old_data_format)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4c9fa92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:59:11.961175Z",
     "iopub.status.busy": "2021-12-28T23:59:11.951740Z",
     "iopub.status.idle": "2021-12-28T23:59:11.964923Z",
     "shell.execute_reply": "2021-12-28T23:59:11.964038Z",
     "shell.execute_reply.started": "2021-12-28T22:14:52.476145Z"
    },
    "papermill": {
     "duration": 4.765417,
     "end_time": "2021-12-28T23:59:11.965118",
     "exception": false,
     "start_time": "2021-12-28T23:59:07.199701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "\n",
    "# from keras.layers import merge, Input\n",
    "# from keras.layers import Dense, Activation, Flatten\n",
    "# from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "# from keras.layers import BatchNormalization\n",
    "# from keras.models import Model\n",
    "# from keras.preprocessing import image\n",
    "# import keras.backend as K\n",
    "\n",
    "# from keras.utils.data_utils import get_file\n",
    "# from keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
    "\n",
    "\n",
    "# TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5'\n",
    "# TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "# TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "# TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "# def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "#     '''The identity_block is the block that has no conv layer at shortcut\n",
    "#     # Arguments\n",
    "#         input_tensor: input tensor\n",
    "#         kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "#         filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "#         stage: integer, current stage label, used for generating layer names\n",
    "#         block: 'a','b'..., current block label, used for generating layer names\n",
    "#     '''\n",
    "#     nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "#     if K.image_dim_ordering() == 'tf':\n",
    "#         bn_axis = 3\n",
    "#     else:\n",
    "#         bn_axis = 1\n",
    "#     conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "#     bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "#     x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a')(input_tensor)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "#     x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "#                       border_mode='same', name=conv_name_base + '2b')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "#     x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "#     x = merge([x, input_tensor], mode='sum')\n",
    "#     x = Activation('relu')(x)\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "#     '''conv_block is the block that has a conv layer at shortcut\n",
    "#     # Arguments\n",
    "#         input_tensor: input tensor\n",
    "#         kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "#         filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "#         stage: integer, current stage label, used for generating layer names\n",
    "#         block: 'a','b'..., current block label, used for generating layer names\n",
    "#     Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "#     And the shortcut should have subsample=(2,2) as well\n",
    "#     '''\n",
    "#     nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "#     if K.image_dim_ordering() == 'tf':\n",
    "#         bn_axis = 3\n",
    "#     else:\n",
    "#         bn_axis = 1\n",
    "#     conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "#     bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "#     x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
    "#                       name=conv_name_base + '2a')(input_tensor)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "#     x = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n",
    "#                       name=conv_name_base + '2b')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "#     x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "#     shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
    "#                              name=conv_name_base + '1')(input_tensor)\n",
    "#     shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "#     x = merge([x, shortcut], mode='sum')\n",
    "#     x = Activation('relu')(x)\n",
    "#     return x\n",
    "\n",
    "\n",
    "# def ResNet50(include_top=True, weights='imagenet',\n",
    "#              input_tensor=None):\n",
    "#     '''Instantiate the ResNet50 architecture,\n",
    "#     optionally loading weights pre-trained\n",
    "#     on ImageNet. Note that when using TensorFlow,\n",
    "#     for best performance you should set\n",
    "#     `image_dim_ordering=\"tf\"` in your Keras config\n",
    "#     at ~/.keras/keras.json.\n",
    "#     The model and the weights are compatible with both\n",
    "#     TensorFlow and Theano. The dimension ordering\n",
    "#     convention used by the model is the one\n",
    "#     specified in your Keras config file.\n",
    "#     # Arguments\n",
    "#         include_top: whether to include the 3 fully-connected\n",
    "#             layers at the top of the network.\n",
    "#         weights: one of `None` (random initialization)\n",
    "#             or \"imagenet\" (pre-training on ImageNet).\n",
    "#         input_tensor: optional Keras tensor (i.e. xput of `layers.Input()`)\n",
    "#             to use as image input for the model.\n",
    "#     # Returns\n",
    "#         A Keras model instance.\n",
    "#     '''\n",
    "#     if weights not in {'imagenet', None}:\n",
    "#         raise ValueError('The `weights` argument should be either '\n",
    "#                          '`None` (random initialization) or `imagenet` '\n",
    "#                          '(pre-training on ImageNet).')\n",
    "#     # Determine proper input shape\n",
    "    \n",
    "#     input_shape = (224, 224, 3)\n",
    "\n",
    "#     if input_tensor is None:\n",
    "#         img_input = Input(shape=input_shape)\n",
    "#     else:\n",
    "#         if not K.is_keras_tensor(input_tensor):\n",
    "#             img_input = Input(tensor=input_tensor)\n",
    "#         else:\n",
    "#             img_input = input_tensor\n",
    "#     if K.image_dim_ordering() == 'tf':\n",
    "#         bn_axis = 3\n",
    "#     else:\n",
    "#         bn_axis = 1\n",
    "\n",
    "#     x = ZeroPadding2D((3, 3))(img_input)\n",
    "#     x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1')(x)\n",
    "#     x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "#     x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "#     x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "#     x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "#     x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "#     x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "#     x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "#     x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "#     x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "#     x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "#     x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "#     x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "#     x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "#     if include_top:\n",
    "#         x = Flatten()(x)\n",
    "#         x = Dense(1000, activation='softmax', name='fc1000')(x)\n",
    "\n",
    "#     model = Model(img_input, x)\n",
    "\n",
    "#     # load weights\n",
    "#     if weights == 'imagenet':\n",
    "#         print('K.image_dim_ordering:', K.image_dim_ordering())\n",
    "#         if K.image_dim_ordering() == 'th':\n",
    "#             if include_top:\n",
    "#                 weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels.h5',\n",
    "#                                         TH_WEIGHTS_PATH,\n",
    "#                                         cache_subdir='models',\n",
    "#                                         md5_hash='1c1f8f5b0c8ee28fe9d950625a230e1c')\n",
    "#             else:\n",
    "#                 weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "#                                         TH_WEIGHTS_PATH_NO_TOP,\n",
    "#                                         cache_subdir='models',\n",
    "#                                         md5_hash='f64f049c92468c9affcd44b0976cdafe')\n",
    "#             model.load_weights(weights_path)\n",
    "#             if K.backend() == 'tensorflow':\n",
    "#                 warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "#                               'are using the Theano '\n",
    "#                               'image dimension ordering convention '\n",
    "#                               '(`image_dim_ordering=\"th\"`). '\n",
    "#                               'For best performance, set '\n",
    "#                               '`image_dim_ordering=\"tf\"` in '\n",
    "#                               'your Keras config '\n",
    "#                               'at ~/.keras/keras.json.')\n",
    "#                 convert_all_kernels_in_model(model)\n",
    "#         else:\n",
    "#             if include_top:\n",
    "#                 weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "#                                         TF_WEIGHTS_PATH,\n",
    "#                                         cache_subdir='models',\n",
    "#                                         md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "#             else:\n",
    "#                 weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "#                                         TF_WEIGHTS_PATH_NO_TOP,\n",
    "#                                         cache_subdir='models',\n",
    "#                                         md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "#             model.load_weights(weights_path)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d603b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:59:20.522370Z",
     "iopub.status.busy": "2021-12-28T23:59:20.521471Z",
     "iopub.status.idle": "2021-12-28T23:59:20.524800Z",
     "shell.execute_reply": "2021-12-28T23:59:20.524238Z",
     "shell.execute_reply.started": "2021-12-28T22:14:53.380066Z"
    },
    "papermill": {
     "duration": 4.400807,
     "end_time": "2021-12-28T23:59:20.524948",
     "exception": false,
     "start_time": "2021-12-28T23:59:16.124141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model2 = VGG19(include_top=False,\n",
    "#              weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e99d4da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:59:28.847964Z",
     "iopub.status.busy": "2021-12-28T23:59:28.846816Z",
     "iopub.status.idle": "2021-12-28T23:59:28.849305Z",
     "shell.execute_reply": "2021-12-28T23:59:28.850034Z",
     "shell.execute_reply.started": "2021-12-28T21:50:37.602949Z"
    },
    "papermill": {
     "duration": 4.193419,
     "end_time": "2021-12-28T23:59:28.850195",
     "exception": false,
     "start_time": "2021-12-28T23:59:24.656776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = model2.output\n",
    "# # x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# model2 = Model(inputs=model2.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07b964fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T23:59:37.548495Z",
     "iopub.status.busy": "2021-12-28T23:59:37.547359Z",
     "iopub.status.idle": "2021-12-28T23:59:37.550725Z",
     "shell.execute_reply": "2021-12-28T23:59:37.550187Z",
     "shell.execute_reply.started": "2021-12-28T21:50:37.660385Z"
    },
    "papermill": {
     "duration": 4.141602,
     "end_time": "2021-12-28T23:59:37.550861",
     "exception": false,
     "start_time": "2021-12-28T23:59:33.409259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # train the model on the new data for a few epochs\n",
    "# init_time = datetime.datetime.now()\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 1, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "\n",
    "# trained = model2.fit(\n",
    "#                     train_images, train_labels,\n",
    "#                     validation_data = (val_images, val_labels),\n",
    "#                     batch_size = BATCH_SIZE, \n",
    "#                     epochs=14,\n",
    "#                     callbacks=[learning_rate_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3612.765676,
   "end_time": "2021-12-28T23:59:46.799469",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-28T22:59:34.033793",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
